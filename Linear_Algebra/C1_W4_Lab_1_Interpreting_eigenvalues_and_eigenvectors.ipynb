{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAt-K2qgcIou"
   },
   "source": [
    "#  Interpreting eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZYK-0rin5x7"
   },
   "source": [
    "Welcome to the Week 4 Lab. Here you will practice finding and interpreting eigenvalues and eigenvectors for various linear transformations.\n",
    "\n",
    "**After this lab you will be able to:**\n",
    "- use Python to find eigenvalues and eigenvectors\n",
    "- visualize and interpret eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [ 1 - Eigenvalues and Eigenvectors: Definition and Interpretation](#1)\n",
    "  - [ 1.1 - Definition of Eigenvalues and Eigenvectors](#1.1)\n",
    "  - [ 1.2 - Finding Eigenvalues and Eigenvectors with Python](#1.2)\n",
    "- [ 2 - Eigenvalues and Eigenvectors of the Standard Transformations in a Plane](#2)\n",
    "  - [ 2.1 - Example 1: Reflection about y-axis (the vertical axis)](#2.1)\n",
    "  - [ 2.2 - Example 2: Shear in x-direction](#2.2)\n",
    "  - [ 2.3 - Example 3: Rotation](#2.3)\n",
    "  - [ 2.4 - Example 4: Identity Matrix and Scaling in All Directions](#2.4)\n",
    "  - [ 2.5 - Example 5: Projection onto x-axis](#2.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI8PBrk_2Z4V"
   },
   "source": [
    "## Packages\n",
    "\n",
    "Run the following cell to load the packages you'll need. The `utils.py` file includes a function you'll use later to plot transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Eigenvalues and Eigenvectors: Definition and Interpretation\n",
    "\n",
    "<a name='1.1'></a>\n",
    "### 1.1 - Definition of Eigenvalues and Eigenvectors\n",
    "\n",
    "Let's consider a linear transformation defined by matrix $A=\\begin{bmatrix}2 & 3 \\\\ 2 & 1 \\end{bmatrix}$. Apply this transformation to the standard basis vectors $e_1=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$ and $e_2=\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$ and visualize the result. Hopefully using a matrix to transform a basis of vectors is familiar from earlier lectures in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "A = np.array([[2, 3],[2, 1]])\n",
    "e1 = np.array([[1],[0]])\n",
    "e2 = np.array([[0],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the function `plot_transformation` defined in `utils.py` to visualize the transformation generated by the matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "utils.plot_transformation(A, e1, e2, vector_name='e');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the original basis vectors $e_1$ and $e_2$ changed their length and direction with the transformation $A$. What if you could choose some other basis vectors where only their lengths will change? This means that for the vector $v$, its transformation will be $Av=\\lambda v$. \n",
    "\n",
    "As you saw in the lectures, a vector $v$ with this property is called an **eigenvector** and the scaling factor $\\lambda$ is called an **eigenvalue**.\n",
    "\n",
    "Note that if $v$ is an eigenvector, so that $Av = \\lambda v$, then any multiple or scaled version of $v$ is also an eigenvector with the same eigenvalue. If we let $k$ represent that scale factor, we would write this mathematically as: \n",
    "\n",
    "$$A(kv)=k(Av)=k \\lambda v = \\lambda (kv),$$ \n",
    "where $k$ is any real valued constant different from zero.\n",
    "\n",
    "In other words, for each eigenvalue, there are infinitely many valid eigenvectors. You can imagine them as all pointing along the same straight line and just having different lengths, or norms. In practice, you will choose just one eigenvector, and it is common to choose the eigenvector which has a norm of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Finding Eigenvalues and Eigenvectors with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python eigenvalues and eigenvectors can be found using the `NumPy` function `np.linalg.eig()`. It returns a tuple consisting of a vector and an array. The vector contains the eigenvalues. The array contains the corresponding eigenvectors, one eigenvector per column. Note that this function chooses the eigenvectors so that they have a norm of 1.\n",
    "\n",
    "With the following code you can find an eigenvalues and eigenvectors for the previously defined matrix $A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "A_eig = np.linalg.eig(A)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"Matrix A:\\n{A} \\n\\nEigenvalues of matrix A:\\n{A_eig[0]}\\n\\nEigenvectors of matrix A:\\n{A_eig[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the first element of the tuple contains the eigenvalues, and the second one has the eigenvectors, one in each column. This means that the first eigenvector can be extrancted with the code `A_eig[1][:,0]` and second eigenvector with the code `A_eig[1][:,1]`. \n",
    "\n",
    "Let's visualize the result of the transformation on the eigenvectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "utils.plot_transformation(A, A_eig[1][:,0], A_eig[1][:,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, $v_1$ is being streched by a factor of 4, while $v_2$ shows a change of the direction, which is equivalent to a factor of -1. Both vectors, however, are still parallel to the direction they were originally pointing and so meet the definition of an eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Eigenvalues and Eigenvectors of some Standard Transformations in a Plane\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Example 1: Reflection about y-axis (the vertical axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to create a reflection about the y-axis, you need to keep the value of the y-axis fixed, while changing the direction of the vector arounf the x-axis. \n",
    "This can be done with the matrix\n",
    "$$A_{\\text{reflection_yaxis}}= \\left[\\begin{matrix}-1& 0\\\\0 &1\\end{matrix}\\right]. $$ \n",
    "\n",
    "<img src = \"./images/reflection.png\" align=\"center\"/>\n",
    "\n",
    "In the following code, you will define the matrix, find its eigenvalues and eigenvectors, and visualize the result How would you interpret this linear transformation in terms of the eigenvectors and thier eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Define transformation matrix A_reflection_yaxis as a numpy array.\n",
    "A_reflection_yaxis = np.array([[-1,0],[0,1]])\n",
    "# Find eigenvalues and eigenvectors of matrix A_reflection_yaxis.\n",
    "A_reflection_yaxis_eig = np.linalg.eig(A_reflection_yaxis)\n",
    "\n",
    "print(f\"Matrix A:\\n {A_reflection_yaxis} \\n\\nEigenvalues of matrix A:\\n {A_reflection_yaxis_eig[0]}\",\n",
    "        f\"\\n\\nEigenvectors of matrix A:\\n {A_reflection_yaxis_eig[1]}\")\n",
    "\n",
    "utils.plot_transformation(A_reflection_yaxis, A_reflection_yaxis_eig[1][:,0],A_reflection_yaxis_eig[1][:,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples you've seen so far, you've considered 2 $\\times$ 2 matrices, and each of them have had 2 distinct eigenvalues, and 2 distinct eigenvectors. A natural question arises: is it always possible to find two different eigenvectors for any linear transformation in the plane? As you already learned in the lectures, the answer is unfortunately no. You'll see a case of this happening in the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Example 2: Shear in x-direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **shear transformation** looks like the image below. This transformation displaces each point in a fixed direction by an amount proportional to its signed distance from a given line parallel to that direction. You can imagine it as slicing the plane into layers and then sliding those layers past one another. Let's explore how many eigenvectors this kind of transformation has.\n",
    "\n",
    "\n",
    "<img src = \"./images/shear_x.png\" align=\"center\"/>\n",
    "\n",
    "\n",
    "To create a matrix transformation that shears in the x-direction, you want to displace the component in the y-direction by some factor, say 0.5. This can be done with the following matrix:\n",
    "\n",
    "$$A_{\\text{shear_x}}= \\left[\\begin{matrix}1& 0.5\\\\0 &1\\end{matrix}\\right]. $$ \n",
    "\n",
    "\n",
    "Note that vector $e_1=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$ will remain the same, and vector $e_2=\\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$ will transform into a vector $\\begin{bmatrix}0.5 \\\\ 1\\end{bmatrix}$.\n",
    "\n",
    "In the next cell, you will define the shear matrix, find the eigenvalues and eigenvectors, and visualize the transformation applied to the eigenvectors you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Define transformation matrix A_shear_x as a numpy array.\n",
    "A_shear_x = np.array([[1, 0.5],[0, 1]])\n",
    "# Find eigenvalues and eigenvectors of matrix A_shear_x.\n",
    "A_shear_x_eig = np.linalg.eig(A_shear_x)\n",
    "\n",
    "print(f\"Matrix A_shear_x:\\n {A_shear_x}\\n\\nEigenvalues of matrix A_shear_x:\\n {A_shear_x_eig[0]}\",\n",
    "      f\"\\n\\nEigenvectors of matrix A_shear_x \\n {A_shear_x_eig[1]}\")\n",
    "\n",
    "utils.plot_transformation(A_shear_x, A_shear_x_eig[1][:,0], A_shear_x_eig[1][:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "A_rotation = np.array([[0, 1],[-1, 0]])\n",
    "A_rotation_eig = np.linalg.eig(A_rotation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Matrix A_rotation:\\n {A_rotation}\\n\\nEigenvalues of matrix A_rotation:\\n {A_rotation_eig[0]}\",\n",
    "      f\"\\n\\nEigenvectors of matrix A_rotation \\n {A_rotation_eig[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are two eigenvalues in the output, but they are actually complex numbers. Note in Python the imaginary part of the complex numbers is indicated with a `j` instead of the $i$ you see more commonly in mathematics. \n",
    "\n",
    "This matrix has two complex eigenvalues and two corresponding complex eigenvectors. Since there are no real eigenvectors, however, we can interpret this result as saying there are no vectors on the plane that will keep their direction after a 90 degree rotation. And think about it, that makes sense. If you rotate the plane, every vector will now be facing in a new direction.\n",
    "\n",
    "If you're less familiar with real vs. complex numbers don't worry. The main point here is that some 2 $\\times$ 2 matrices will only have one or zero real eigenvectors, and hopefully you're developing intuition for why that's the case. If there are no vectors that point in the same direction after the matrix transformation is applied, we wouldn't expect to find any eigenvectors. With that in mind, let's look at another interesting example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "### 2.4 - Example 4: Identity Matrix and Scaling in All Directions\n",
    "\n",
    "What happens if we transform the plane using the identity matrix? This means that there will be no change to any vector in the plane. Since every point and vector does not move at all, in this case every vector is still facing in the same direction, and every vectors meets the definition of an eigenvector.\n",
    "\n",
    "In the next cell, you will explore what kinds of output you get from `NumPy` when you try to calculate the eigenvalues and eigenvectors of the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "A_identity = np.array([[1, 0],[0, 1]])\n",
    "A_identity_eig = np.linalg.eig(A_identity)\n",
    "\n",
    "utils.plot_transformation(A_identity, A_identity_eig[1][:,0], A_identity_eig[1][:,1]);\n",
    "\n",
    "print(f\"Matrix A_identity:\\n {A_identity}\\n\\nEigenvalues of matrix A_identity:\\n {A_identity_eig[0]}\",\n",
    "      f\"\\n\\nEigenvectors of matrix A_identity\\n {A_identity_eig[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the out of the `np.linalg.eig()` function shows that there are two eigenvalues that are equal to each other $\\lambda = 1$, which is true. But the list of eigenvectors does not cover all of them. It can be shown algebraically that all of the vectors will be eigenvectors for identity matrix. Using software, you can't see it sometimes, so be careful! That's why understanding of mathematical objects behind your code and models is so important.\n",
    "\n",
    "Check that the same will happen finding eigenvectors for the scaling (dilation) in both directions x and y by factor of $2$. In this case every vector is facing the same direction as it was before, but twice as long. Once again, every vector meets the definition of an eigenvector, but `NumPy` will only provide two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "A_scaling = np.array([[2, 0],[0, 2]])\n",
    "A_scaling_eig = np.linalg.eig(A_scaling)\n",
    "\n",
    "utils.plot_transformation(A_scaling, A_scaling_eig[1][:,0], A_scaling_eig[1][:,1]);\n",
    "\n",
    "print(f\"Matrix A_scaling:\\n {A_scaling}\\n\\nEigenvalues of matrix A_scaling:\\n {A_scaling_eig[0]}\",\n",
    "      f\"\\n\\nEigenvectors of matrix A_scaling\\n {A_scaling_eig[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2.5'></a>\n",
    "### 2.5 - Example 5: Projection onto x-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate one last interesting example: projection onto the x-axis. This transformation keeps only the x component of the vector and sets all y-values to 0.\n",
    "\n",
    "The transformation that projects onto the x-axis can be defined by the matrix\n",
    "$$A_{\\text{projection}}=\\begin{bmatrix}1 & 0 \\\\ 0 & 0 \\end{bmatrix}.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "A_projection = np.array([[1, 0],[0, 0]])\n",
    "A_projection_eig = np.linalg.eig(A_projection)\n",
    "\n",
    "utils.plot_transformation(A_projection, A_projection_eig[1][:,0], A_projection_eig[1][:,1]);\n",
    "\n",
    "\n",
    "print(f\"Matrix A_projection:\\n {A_projection}\\n\\nEigenvalues of matrix A_projection:\\n {A_projection_eig[0]}\",\n",
    "      f\"\\n\\nEigenvectors of matrix A_projection\\n {A_projection_eig[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix has two real eigenvalues, and one of them is equal to $0$. There is nothing wrong with this, $\\lambda$ can be equal to $0$! In this case, this just means that anything that lies on the y-axis will be sent to zero, since it has no component in the x-direction. Since there are two distinct eigenvalues, the transformation still has two eigenvectors.\n",
    "\n",
    "Congratulations! You have reached the end of this lab. Hopefully by now you have a clearer intuition about what eigenvalues and eigenvectors represent, and why different 2 $\\times$ 2 matrices have different numbers of eigenvectors."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "grader_version": "2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "478841ab876a4250505273c8a697bbc1b6b194054b009c227dc606f17fb56272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
